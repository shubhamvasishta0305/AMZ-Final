const express = require('express');
const path = require('path');
const cors = require('cors');
const axios = require('axios');
const { parse } = require('csv-parse/sync');
const { spawn } = require('child_process');

const app = express();
const PORT = process.env.PORT || 3000; 
// Middleware
app.use(cors());
app.use(express.json());
app.use(express.static('public'));
app.use(express.urlencoded({ extended: true }));

// Your Google Sheet CSV URL
const SHEET_CSV_URL = 
`https://docs.google.com/spreadsheets/d/1C6s96_hmDTYjwwkq5r4ekAh5FrtAvPJqN54WwYl_eVI/export?format=csv&gid=75817034`;

// Golden URL Sheet CSV URL (Page 2)
const GOLDEN_SHEET_CSV_URL = 
`https://docs.google.com/spreadsheets/d/1C6s96_hmDTYjwwkq5r4ekAh5FrtAvPJqN54WwYl_eVI/export?format=csv&gid=62256398`;

// Cache for sheet data
let sheetDataCache = null;
let lastCacheTime = null;

// Cache for golden sheet data
let goldenSheetDataCache = null;
let lastGoldenCacheTime = null;

// Function to get real data from Google Sheets CSV
async function getRealSheetData() {
    // Return cached data if it's fresh (5 minutes)
    if (sheetDataCache && lastCacheTime && (Date.now() - lastCacheTime) < 3000000) {
        console.log('üìä Using cached sheet data');
        return sheetDataCache;
    }

    try {
        console.log('üìä Fetching fresh data from Google Sheets CSV...');
        const response = await axios.get(SHEET_CSV_URL, { 
            timeout: 15000,
            headers: {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
        });
        
        const csvData = response.data;
        
        // Debug: Log first 200 characters to see what we're receiving
        console.log('üìù First 200 chars of response:', csvData.substring(0, 200));
        console.log('üìù Response type:', typeof csvData);
        
        // Parse CSV
        const records = parse(csvData, {
            columns: true,
            skip_empty_lines: true,
            trim: true,
            relax_quotes: true,
            relax_column_count: true
        });

        console.log('‚úÖ Successfully parsed', records.length, 'rows from Google Sheets');
        
        // Cache the data
        sheetDataCache = {
            success: true,
            data: records,
            headers: Object.keys(records[0] || {})
        };
        lastCacheTime = Date.now();
        
        return sheetDataCache;
        
    } catch (error) {
        console.error('‚ùå Error fetching from Google Sheets CSV:', error.message);
        
        // If it's an axios error, log the response
        if (error.response) {
            console.error('üìç Status:', error.response.status);
            console.error('üìç Response preview:', error.response.data?.substring(0, 200));
        }
        
        // Return comprehensive fallback data
        return {
            success: true,
            data: [
                { '': 'Clothing', Gender: 'Women', 'Age Group': 'Adults', Subcategory: 'Kurtas', URL: 'https://www.amazon.in/s?k=women+kurtas' },
                { '': 'Clothing', Gender: 'Women', 'Age Group': 'Adults', Subcategory: 'Sarees', URL: 'https://www.amazon.in/s?k=women+sarees' },
                { '': 'Clothing', Gender: 'Women', 'Age Group': 'Adults', Subcategory: 'Dresses', URL: 'https://www.amazon.in/s?k=women+dresses' },
                { '': 'Clothing', Gender: 'Men', 'Age Group': 'Adults', Subcategory: 'Shirts', URL: 'https://www.amazon.in/s?k=men+shirts' },
                { '': 'Clothing', Gender: 'Men', 'Age Group': 'Adults', Subcategory: 'T-Shirts', URL: 'https://www.amazon.in/s?k=men+t+shirts' }
            ],
            headers: ['', 'Gender', 'Age Group', 'Subcategory', 'URL'],
            fromCache: true
        };
    }
}

// Function to get golden sheet data (Page 2)
async function getGoldenSheetData() {
    // Return cached data if it's fresh (5 minutes)
    // if (goldenSheetDataCache && lastGoldenCacheTime && (Date.now() - lastGoldenCacheTime) < 3000000) {
    //     console.log('üìä Using cached golden sheet data');
    //     return goldenSheetDataCache;
    // }

    try {
        console.log('üìä Fetching fresh data from Golden Sheet CSV...');
        const response = await axios.get(GOLDEN_SHEET_CSV_URL, { 
            timeout: 15000,
            headers: {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
        });
        
        const csvData = response.data;
        
        // Debug: Log first 200 characters to see what we're receiving
        console.log('üìù First 200 chars of golden sheet response:', csvData.substring(0, 200));
        console.log('üìù Response type:', typeof csvData);
        
        // Parse CSV
        const records = parse(csvData, {
            columns: true,
            skip_empty_lines: true,
            trim: true,
            relax_quotes: true,
            relax_column_count: true
        });

        console.log('‚úÖ Successfully parsed', records.length, 'rows from Golden Sheet');
        
        // Cache the data
        goldenSheetDataCache = {
            success: true,
            data: records,
            headers: Object.keys(records[0] || {})
        };
        lastGoldenCacheTime = Date.now();
        
        return goldenSheetDataCache;
        
    } catch (error) {
        console.error('‚ùå Error fetching from Golden Sheet CSV:', error.message);
        
        // If it's an axios error, log the response
        if (error.response) {
            console.error('üìç Status:', error.response.status);
            console.error('üìç Response preview:', error.response.data?.substring(0, 200));
        }
        
        // Return empty fallback data
        return {
            success: true,
            data: [],
            headers: [],
            fromCache: false
        };
    }
}

// API endpoint to get filtered subcategories
app.get('/api/filtered-subcategories', async (req, res) => {
    const { category, gender, ageGroup } = req.query;
    
    console.log('üîç Filtering for:', { category, gender, ageGroup });
    
    try {
        const sheetResult = await getRealSheetData();
        const data = sheetResult.data;

        // Filter and get unique subcategories
        const filteredSubcategories = [];
        const seenSubcategories = new Set();

        data.forEach(row => {
            // Get category from the first unnamed column (empty string key)
            const rowCategory = row[''] || row.Category;
            const rowGender = row.Gender || row.gender;
            const rowAgeGroup = row['Age Group'] || row.AgeGroup || row.agegroup;
            const rowSubcategory = row.Subcategory || row['Sub Category'] || row.subcategory;

            if (rowCategory && rowCategory.toString().trim() === category &&
                rowGender && rowGender.toString().trim() === gender &&
                rowAgeGroup && rowAgeGroup.toString().trim() === ageGroup &&
                rowSubcategory) {
                
                const subcat = rowSubcategory.toString().trim();
                if (!seenSubcategories.has(subcat)) {
                    filteredSubcategories.push(subcat);
                    seenSubcategories.add(subcat);
                }
            }
        });

        console.log('üìã Found', filteredSubcategories.length, 'subcategories:', filteredSubcategories);

        res.json({
            success: true,
            subcategories: filteredSubcategories.sort()
        });
    } catch (error) {
        console.error('‚ùå Error fetching subcategories:', error.message);
        res.status(500).json({ 
            success: false, 
            error: 'Failed to fetch subcategories: ' + error.message 
        });
    }
});

// API endpoint to find matching URL
app.get('/api/find-url', async (req, res) => {
    const { category, gender, ageGroup, subcategory } = req.query;
    
    console.log('üîç Finding URL for:', { category, gender, ageGroup, subcategory });
    
    try {
        const sheetResult = await getRealSheetData();
        const data = sheetResult.data;

        // Find matching row
        const matchingRow = data.find(row => {
            const rowCategory = row[''] || row.Category;
            const rowGender = row.Gender || row.gender;
            const rowAgeGroup = row['Age Group'] || row.AgeGroup || row.agegroup;
            const rowSubcategory = row.Subcategory || row['Sub Category'] || row.subcategory;
            const rowURL = row.URL || row.Url || row.url;

            return (rowCategory && rowCategory.toString().trim() === category &&
                    rowGender && rowGender.toString().trim() === gender &&
                    rowAgeGroup && rowAgeGroup.toString().trim() === ageGroup &&
                    rowSubcategory && rowSubcategory.toString().trim() === subcategory);
        });

        const url = matchingRow ? (matchingRow.URL || matchingRow.Url || matchingRow.url) : null;

        if (matchingRow && url) {
            res.json({
                success: true,
                url: url,
                found: true
            });
        } else {
            res.json({
                success: true,
                url: null,
                found: false,
                message: 'No matching URL found for the selected criteria'
            });
        }
    } catch (error) {
        console.error('‚ùå Error finding URL:', error.message);
        res.status(500).json({ 
            success: false, 
            error: 'Failed to find URL: ' + error.message 
        });
    }
});

// Helper function to clean and format scraped data for frontend
function formatScrapedData(rawData) {
    // Helper to clean keys - remove newlines, special characters, and extra spaces
    const cleanKey = (key) => {
        return key
            .replace(/\n/g, ' ')
            .replace(/\u200f|\u200e/g, '') // Remove RTL/LTR marks
            .replace(/\s+/g, ' ')
            .replace(/\s*:\s*$/, '')
            .trim();
    };

    // Helper to clean object keys
    const cleanObjectKeys = (obj) => {
        if (!obj || typeof obj !== 'object') return obj;
        
        const cleaned = {};
        for (let key in obj) {
            const cleanedKey = cleanKey(key);
            cleaned[cleanedKey] = obj[key];
        }
        return cleaned;
    };

    // Format product details as array for easier frontend rendering
    const formatDetailsAsArray = (obj) => {
        if (!obj || typeof obj !== 'object') return [];
        
        return Object.entries(obj)
            .filter(([key, value]) => key && value && key !== 'status')
            .map(([key, value]) => ({
                label: cleanKey(key),
                value: value
            }));
    };

    return {
        success: true,
        product: {
            title: rawData.title || 'N/A',
            description: rawData.description || 'N/A',
            asin: rawData.asin || 'N/A',
            images: rawData.images || []
        },
        details: {
            featureBullets: rawData.bullets || [],
            productDetails: formatDetailsAsArray(rawData.productDetails),
            manufacturingDetails: formatDetailsAsArray(rawData.manufacturingDetails),
            additionalInfo: formatDetailsAsArray(rawData.additionalInfo)
        },
        // Also include cleaned raw format for flexibility
        raw: {
            productDetails: cleanObjectKeys(rawData.productDetails),
            manufacturingDetails: cleanObjectKeys(rawData.manufacturingDetails),
            additionalInfo: cleanObjectKeys(rawData.additionalInfo)
        }
    };
}

// Helper function to format details as array for frontend
function formatDetailsAsArray(obj) {
    if (!obj || typeof obj !== 'object') return [];
    
    return Object.entries(obj)
        .filter(([key, value]) => key && value && key !== 'status')
        .map(([key, value]) => ({
            label: key.trim(),
            value: value
        }));
}

// Dual Scraper Integration - amz_scraper for images, scraper.py for other data
app.post('/api/scrape-product', async (req, res) => {
    const { url } = req.body;
    
    if (!url) {
        return res.status(400).json({ success: false, error: 'URL is required' });
    }

    console.log('üîç Starting dual scraping for URL:', url);

    try {
        // Run both scrapers in parallel
        const scraperPromise = new Promise((resolve, reject) => {
            const scraperProcess = spawn('python3', ['scraper.py', url]);
            let scraperData = '';
            let scraperError = '';

            scraperProcess.stdout.on('data', (data) => {
                scraperData += data.toString();
            });

            scraperProcess.stderr.on('data', (data) => {
                scraperError += data.toString();
                console.log('scraper.py stderr:', data.toString());
            });

            scraperProcess.on('close', (code) => {
                if (code === 0 && scraperData) {
                    try {
                        resolve(JSON.parse(scraperData));
                    } catch (e) {
                        reject(new Error('Failed to parse scraper.py output'));
                    }
                } else {
                    reject(new Error(`scraper.py failed with code ${code}`));
                }
            });
        });

        const amzScraperPromise = new Promise((resolve, reject) => {
            const amzProcess = spawn('python3', ['amz_scraper.py', url, '--formatted']);
            let amzData = '';
            let amzError = '';

            amzProcess.stdout.on('data', (data) => {
                amzData += data.toString();
            });

            amzProcess.stderr.on('data', (data) => {
                amzError += data.toString();
                console.log('amz_scraper.py stderr:', data.toString());
            });

            amzProcess.on('close', (code) => {
                if (code === 0 && amzData) {
                    try {
                        resolve(JSON.parse(amzData));
                    } catch (e) {
                        reject(new Error('Failed to parse amz_scraper.py output'));
                    }
                } else {
                    reject(new Error(`amz_scraper.py failed with code ${code}`));
                }
            });
        });

        // Wait for both scrapers to complete
        const [scraperResult, amzScraperResult] = await Promise.all([scraperPromise, amzScraperPromise]);

        console.log('‚úÖ Both scrapers completed successfully');

        // Merge results: scraper.py data + amz_scraper images
        const mergedResult = {
            success: true,
            product: {
                title: scraperResult.title || 'N/A',
                description: scraperResult.description || 'N/A',
                // asin: scraperResult.asin || amzScraperResult.product?.asin || 'N/A',
                images: amzScraperResult.product?.images || []  // Images from amz_scraper
            },
            details: {
                featureBullets: scraperResult.bullets || [],
                productDetails: formatDetailsAsArray(scraperResult.productDetails),
                manufacturingDetails: formatDetailsAsArray(scraperResult.manufacturingDetails),
                additionalInfo: formatDetailsAsArray(scraperResult.additionalInfo)
            },
            raw: {
                productDetails: scraperResult.productDetails,
                manufacturingDetails: scraperResult.manufacturingDetails,
                additionalInfo: scraperResult.additionalInfo
            }
        };

        console.log('üì¶ Merged result:', JSON.stringify(mergedResult, null, 2));
        res.json(mergedResult);

    } catch (error) {
        console.error('‚ùå Scraping error:', error.message);
        res.json({
            success: false,
            error: error.message,
            message: 'Server error during scraping'
        });
    }
});

// API endpoint to get all sheet data
app.get('/api/sheet-data', async (req, res) => {
    try {
        const sheetResult = await getRealSheetData();
        
        res.json({
            success: true,
            data: sheetResult.data,
            headers: sheetResult.headers,
            totalRows: sheetResult.data.length,
            fromCache: sheetResult.fromCache || false
        });
    } catch (error) {
        console.error('‚ùå Error fetching sheet data:', error.message);
        res.status(500).json({ 
            success: false, 
            error: 'Failed to fetch sheet data: ' + error.message 
        });
    }
});

// API endpoint to get golden sheet data (Page 2)
app.get('/api/golden-sheet-data', async (req, res) => {
    try {
        const sheetResult = await getGoldenSheetData();
        
        res.json({
            success: true,
            data: sheetResult.data,
            headers: sheetResult.headers,
            totalRows: sheetResult.data.length,
            fromCache: sheetResult.fromCache || false
        });
    } catch (error) {
        console.error('‚ùå Error fetching golden sheet data:', error.message);
        res.status(500).json({ 
            success: false, 
            error: 'Failed to fetch golden sheet data: ' + error.message 
        });
    }
});

// Debug endpoint
app.get('/api/debug-sheet', async (req, res) => {
    try {
        const sheetResult = await getRealSheetData();
        
        const allData = sheetResult.data.map(row => ({
            firstColumn: row[''], // Category column
            gender: row.Gender,
            ageGroup: row['Age Group'],
            subcategory: row.Subcategory,
            url: row.URL,
            raw: row
        }));

        const uniqueValues = {
            categories: [...new Set(allData.map(row => row.firstColumn).filter(Boolean))],
            genders: [...new Set(allData.map(row => row.gender).filter(Boolean))],
            ageGroups: [...new Set(allData.map(row => row.ageGroup).filter(Boolean))],
            subcategories: [...new Set(allData.map(row => row.subcategory).filter(Boolean))]
        };

        res.json({
            success: true,
            totalRows: sheetResult.data.length,
            uniqueValues: uniqueValues,
            sampleData: allData.slice(0, 5),
            rawFirstRow: sheetResult.data[0]
        });
    } catch (error) {
        res.status(500).json({ 
            success: false, 
            error: 'Failed to debug sheet: ' + error.message 
        });
    }
});

app.post('/api/submit-listing', (req, res) => {
    console.log('üì¶ Listing submitted:', req.body);
    res.json({ 
        success: true, 
        message: 'Listing submitted successfully',
        submittedData: req.body
    });
});

// Serve main page
app.get('/', (req, res) => {
    res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

// Serve scraper page
app.get('/scraper', (req, res) => {
    res.sendFile(path.join(__dirname, 'public', 'scraper.html'));
});

// Serve test page
app.get('/test-sheet', (req, res) => {
    res.sendFile(path.join(__dirname, 'public', 'simple-test.html'));
});

// Start server
app.listen(PORT, () => {
    console.log(`üöÄ Server running on http://localhost:${PORT}`);
    console.log(`üìä Google Sheets integration: ACTIVE`);
    console.log(`üîç Python Scraper: READY (with mock data fallback)`);
    console.log(`üí° Main App: http://localhost:${PORT}`);
    console.log(`üîß Scraper UI: http://localhost:${PORT}/scraper`);
    console.log(`üêõ Debug: http://localhost:${PORT}/api/debug-sheet`);
});